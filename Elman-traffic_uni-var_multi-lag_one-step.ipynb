{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab5488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd1674a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>MAXIMUM_SPEED</th>\n",
       "      <th>MINIMUM_SPEED</th>\n",
       "      <th>AVERAGE_SPEED</th>\n",
       "      <th>NUMBER_OF_VEHICLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "      <td>63</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>145</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>148</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE_TIME  MAXIMUM_SPEED  MINIMUM_SPEED  AVERAGE_SPEED  \\\n",
       "0 2022-01-01 00:00:00            133              1             60   \n",
       "1 2022-01-01 01:00:00            133              8             63   \n",
       "2 2022-01-01 02:00:00            139              7             69   \n",
       "3 2022-01-01 03:00:00            145              3             61   \n",
       "4 2022-01-01 04:00:00            148              6             73   \n",
       "\n",
       "   NUMBER_OF_VEHICLES  \n",
       "0                 149  \n",
       "1                 130  \n",
       "2                 101  \n",
       "3                  90  \n",
       "4                  55  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datayı Yükleyelim\n",
    "path = r'c:\\sxk990_6ay.xlsx'\n",
    "data = pd.read_excel(path, date_format=[0])\n",
    "# İlk 5 Satır\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93b441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Datetime Haline Getirilmesi\n",
    "data['DATE_TIME'] = pd.to_datetime(data.DATE_TIME, format='%Y-%m-%d %H:%M')\n",
    "#İndex'e Alınması\n",
    "data.index = data.DATE_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(48,12))\n",
    "data.AVERAGE_SPEED.plot(label='hiz')\n",
    "plt.legend(loc='best')\n",
    "plt.title('1 Hour Speed Rates', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f653d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = data['AVERAGE_SPEED'].values.reshape(-1,1)\n",
    "values = values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463bca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %60 Train % 40 Test\n",
    "TRAIN_SIZE = 0.60\n",
    "train_size = int(len(dataset) * TRAIN_SIZE)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(\"Veri Seti Sayıları (training set, test set): \" + str((len(train), len(test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7add13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, window_size):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - window_size - 1):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[(i + window_size), 0])\n",
    "    return(np.array(data_X), np.array(data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c56ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verisetlerimizi Oluşturalım\n",
    "window_size = 6\n",
    "train_X, train_Y = create_dataset(train, window_size)\n",
    "test_X, test_Y = create_dataset(test, window_size)\n",
    "print(\"Original train data shape:\")\n",
    "print(train_X.shape)\n",
    "print(\"Original train hedef data shape:\")\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a15b18-918e-4e6e-9944-2cc312ad5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_act(x, der=False):\n",
    "   import numpy as np\n",
    "\n",
    "   if (der == True):  # Turev sigmoid\n",
    "      f = 1 / (1 + np.exp(- x)) * (1 - 1 / (1 + np.exp(- x)))\n",
    "\n",
    "   else:  # sigmoid\n",
    "      f = 1 / (1 + np.exp(- x))\n",
    "\n",
    "   return f\n",
    "\n",
    "def tanh_act(x, der=False):\n",
    "   import numpy as np\n",
    "\n",
    "   if (der == True):  # Turev tanh\n",
    "      f = 1 - np.square(((np.exp(x)) - (np.exp(-x))) / ((np.exp(x)) + (np.exp(-x))))\n",
    "   else:\n",
    "      f = ((np.exp(x)) - (np.exp(-x))) / ((np.exp(x)) + (np.exp(-x)))\n",
    "\n",
    "   return f\n",
    "\n",
    "def Lineer_act(x, der=False):\n",
    "   import numpy as np\n",
    "\n",
    "   if (der == True):  # the derivative of the ReLU is the Heaviside Theta\n",
    "      f = 1\n",
    "   else:\n",
    "      f = x\n",
    "\n",
    "   return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = window_size    # Gizli Katman Giris neron sayisi\n",
    "n = 6    # Gizli Katman Durum neron sayisi\n",
    "q = 1    # Cikis Katmani neron sayisi\n",
    "\n",
    "eta = 2 / 100        # Learning rate\n",
    "alpha = 9 / 100      # Momentum\n",
    "\n",
    "#X1 = np.array([0.05,0.025,0.025,0.0025,0.025])        # X1 : x(k-1) baslangic degerleri 0 aliyoruz\n",
    "X1 = 0.25 * np.random.normal(0, np.sqrt(0.01), n)\n",
    "\n",
    "Wu2 = np.zeros((n, m))              # Wu2 : Wu(k-2) momentum icin\n",
    "Wu1 = 0.25 * np.random.randn(n, m)  # Wu1 : Wu(k-1)  Gizli Katman Giris Agirlik Degerleri\n",
    "\n",
    "Wx2 = np.zeros((n, n))              # Wx2 : Wx(k-2) momentum icin\n",
    "Wx1 = 0.25 * np.random.randn(n, n)  # Wx1 : Wx(k-1) Gizli Katman Durum Agirlik Degerleri\n",
    "b1 = 0.25 * np.random.randn(n)\n",
    "\n",
    "Wy2 = np.zeros((q, n))              # Wy2 : Wy(k-2) momentum icin\n",
    "Wy1 = 0.25 * np.random.randn(q, n)  # Wy1 : Wy(k-1) Cikis Katmani Agirlik Degerleri\n",
    "bOut = 0.25 * np.random.randn(q)\n",
    "\n",
    "E_ani_max = []\n",
    "E_ort = []\n",
    "epoch = 1000                      # Iterasyon Sayisi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b750e-5e4a-412c-bc5c-7fd832504a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in range(epoch):\n",
    "    E_ani = []\n",
    "   \n",
    "    for k in range(np.size(train_X, 0)):\n",
    "     \n",
    "      # 1: Egitim Veri Seti Girisi\n",
    "      \n",
    "     u = train_X[k]\n",
    "\n",
    "     # 2: Feed forward\n",
    "    \n",
    "     v = np.dot(Wu1, u) + np.dot(Wx1, X1) + b1    \n",
    "     X1 = tanh_act(v)                 # 1. Katman Cikisi\n",
    "     y = np.dot(Wy1, X1) + bOut       # Cikis Katmani Cikisi    \n",
    "     e = train_Y[k] - y\n",
    " \n",
    "    \n",
    "     # 3: Gradient descent\n",
    "    \n",
    "     Wu = Wu1 + (eta * np.dot((np.dot( Wy1.T , e.reshape(q, 1) ) * (tanh_act(v, der=True)).reshape(n,1)) , u.reshape(1, m))) + alpha * (Wu1 - Wu2)\n",
    "     Wy = Wy1 + (eta * np.dot( e.reshape(q,1) , X1.reshape(1,n))) + alpha * (Wy1 - Wy2)\n",
    "     Wx = Wx1 + (eta * np.dot((np.dot( Wy1.T , e.reshape(q, 1) ) * (tanh_act(v, der=True)).reshape(n,1)) , X1.reshape(1,n))) + alpha * (Wx1 - Wx2)\n",
    "    \n",
    "\n",
    "     Wu2 = Wu1\n",
    "     Wu1 = Wu\n",
    "     Wy2 = Wy1\n",
    "     Wy1 = Wy\n",
    "     Wx2 = Wx1\n",
    "     Wx1 = Wx\n",
    "    \n",
    "     # 4. loss function Hesaplama\n",
    "    \n",
    "     E_ani.append((1 / 2) * np.dot(e.T, e) )\n",
    "\n",
    "    E_ort.append((1 / np.size(train_X, 0)) * sum(E_ani))\n",
    "    E_ani_max.append(max(E_ani))\n",
    "    if l >= 21:\n",
    "      if abs((E_ort[l - 1]) - (E_ort[l])) <= 0.0000000001 or (E_ort[l - 20]) - (E_ort[l]) <  -0.0005  :\n",
    "          print(\"E_ort_degisim=\", (E_ort[l - 20]) - (E_ort[l]))\n",
    "          break\n",
    "#print(\"E_ort=\",E_ort)\n",
    "print(\"l=\",l)\n",
    "\n",
    "# 5. Her Iterasyon icin hatayi cizdiriyoruz\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(E_ort)\n",
    "plt.title('Loss for each training data point', fontsize=20)\n",
    "plt.xlabel('Training data', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b6674",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_ani_tr = []\n",
    "E_ort_tr = []\n",
    "pred_train_Y  = []\n",
    "\n",
    "# 6. Train Veri Seti Loss hesaplama\n",
    "\n",
    "\n",
    "for m in range(np.size(train_X, 0)):\n",
    "\n",
    "    x_tr = train_X[m]   \n",
    "    v_tr = np.dot(Wu1, x_tr) + np.dot(Wx1, X1) + b1\n",
    "    X1 = tanh_act(v_tr)                 # 1. Katman Cikisi\n",
    "    y_tr = np.dot(Wy1, X1) + bOut     # Cikis Katmani Cikisi\n",
    "    e_tr = train_Y[m] - y_tr    \n",
    "    pred_train_Y.append(y_tr)\n",
    "    \n",
    "    # Train loss function Hesaplama\n",
    "    \n",
    "    E_ani_tr.append((1 / 2) * np.dot(e_tr.T, e_tr) )\n",
    "    E_ort_tr.append((1 / np.size(train_X, 0)) * sum(E_ani_tr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_ani_t = []\n",
    "E_ort_t = []\n",
    "pred_test_Y  = []\n",
    "\n",
    "# 7. Test Veri Seti Loss Hesaplama\n",
    "\n",
    "\n",
    "for m in range(np.size(test_X, 0)):\n",
    "    \n",
    "    x_t = test_X[m]   \n",
    "    v_t = np.dot(Wu1, x_t) + np.dot(Wx1, X1) + b1\n",
    "    X1 = tanh_act(v_t)                 # 1. Katman Cikisi\n",
    "    y_t = np.dot(Wy1, X1) + bOut     # Cikis Katmani Cikisi\n",
    "    e_t = test_Y[m] - y_t    \n",
    "    pred_test_Y.append(y_t)\n",
    "    \n",
    "    # Test loss function Hesaplama\n",
    "    \n",
    "    E_ani_t.append((1 / 2) * np.dot(e_t.T, e_t) )\n",
    "    E_ort_t.append((1 / np.size(test_X, 0)) * sum(E_ani_t))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b86928",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Tahminleri 0-1 ile scale edilmiş halinden geri çeviriyoruz.\n",
    "pred_train_Y = np.array(pred_train_Y)  \n",
    "pred_train_Y = scaler.inverse_transform((pred_train_Y).reshape(-1, 1))\n",
    "train_Y = scaler.inverse_transform((train_Y).reshape(-1, 1))\n",
    "\n",
    "pred_test_Y = np.array(pred_test_Y)    \n",
    "pred_test_Y = scaler.inverse_transform((pred_test_Y).reshape(-1, 1))\n",
    "test_Y = scaler.inverse_transform((test_Y).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tr = math.sqrt(mean_squared_error(train_Y, pred_train_Y))\n",
    "print(\"Train data score: %.2f RMSE\" % score_tr)\n",
    "\n",
    "score_t = math.sqrt(mean_squared_error(test_Y, pred_test_Y))\n",
    "print(\"Test data score: %.2f RMSE\" % score_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "error_mape_tr = 100*mean_absolute_percentage_error(train_Y, pred_train_Y)\n",
    "print(\"Train data score: %.2f MAPE\" % error_mape_tr)\n",
    "\n",
    "error_mape_t = 100*mean_absolute_percentage_error(test_Y, pred_test_Y)\n",
    "print(\"Test data score: %.2f MAPE\" % error_mape_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d690ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdape_t = np.median((np.abs(np.subtract(train_Y, pred_train_Y)/ train_Y))) * 100\n",
    "print(\"Train data score: %.2f MdAPE\" % mdape_t)\n",
    "\n",
    "mdape_t = np.median((np.abs(np.subtract(test_Y, pred_test_Y)/ test_Y))) * 100\n",
    "print(\"Test data score: %.2f MdAPE\" % mdape_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3687107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "\n",
    "error_smape_tr = smape(train_Y,pred_train_Y)\n",
    "print(\"Train data score: %.2f SMAPE\" % error_smape_tr)\n",
    "error_smape_t = smape(test_Y,pred_test_Y)\n",
    "print(\"Test data score: %.2f SMAPE\" % np.mean(error_smape_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "e_tr = train_Y - pred_train_Y\n",
    "scale = mean_absolute_error(train_Y[1:], train_Y[:-1])\n",
    "mase_tr = np.mean(np.abs(e_tr / scale))\n",
    "print(\"Train data score: %.2f MASE\" % mase_tr)\n",
    "\n",
    "e_t = test_Y - pred_test_Y\n",
    "scale = mean_absolute_error(test_Y[1:], test_Y[:-1])\n",
    "mase_t = np.mean(np.abs(e_t / scale))\n",
    "print(\"Test data score: %.2f MASE\" % mase_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ve Test Veri Seti icin Ag sonucu ve verili cikislari cizdiriyoruz\n",
    "\n",
    "\n",
    "plt.figure(figsize=(48, 16))\n",
    "plt.plot(pred_train_Y, label = \"Train verisi Tahmin\")\n",
    "plt.plot(train_Y, label = \"Train verisi Gerçek\")\n",
    "plt.title('Train verisi Tahmin ve Gercek zamanla degisimi', fontsize=32)\n",
    "plt.xlabel('Zaman', fontsize=32)\n",
    "plt.ylabel('Hız Değerleri', fontsize=32)\n",
    "plt.legend(fontsize=32)\n",
    "plt.show()\n",
    "#plt.savefig('MLP_Mnas_15k_iter.png')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(48, 16))\n",
    "plt.plot(pred_test_Y, label = \"Test verisi Tahmin\")\n",
    "plt.plot(test_Y, label = \"Test verisi Gerçek\")\n",
    "plt.title('Test verisi Tahmin ve Gercek zamanla degisimi', fontsize=32)\n",
    "plt.xlabel('Zaman', fontsize=32)\n",
    "plt.ylabel('Hız Değerleri', fontsize=32)\n",
    "plt.legend(fontsize=32)\n",
    "plt.show()\n",
    "#plt.savefig('MLP_Mnas_15k_iter.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
